{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-05-21T08:51:21.275857Z","iopub.execute_input":"2024-05-21T08:51:21.277265Z","iopub.status.idle":"2024-05-21T08:51:22.372329Z","shell.execute_reply.started":"2024-05-21T08:51:21.277201Z","shell.execute_reply":"2024-05-21T08:51:22.371132Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read the CSV file containing the IMDB movie reviews dataset into a DataFrame.\ndf = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:22.374102Z","iopub.execute_input":"2024-05-21T08:51:22.374557Z","iopub.status.idle":"2024-05-21T08:51:24.003920Z","shell.execute_reply.started":"2024-05-21T08:51:22.374526Z","shell.execute_reply":"2024-05-21T08:51:24.002683Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Count the occurrences of each unique value in the 'sentiment' column of the DataFrame and display the result.\ndf['sentiment'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:24.005473Z","iopub.execute_input":"2024-05-21T08:51:24.005932Z","iopub.status.idle":"2024-05-21T08:51:24.034581Z","shell.execute_reply.started":"2024-05-21T08:51:24.005893Z","shell.execute_reply":"2024-05-21T08:51:24.033233Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"sentiment\npositive    25000\nnegative    25000\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values in each column of the DataFrame and display the total count of missing values for each column.\ndf.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:24.037777Z","iopub.execute_input":"2024-05-21T08:51:24.038169Z","iopub.status.idle":"2024-05-21T08:51:24.062077Z","shell.execute_reply.started":"2024-05-21T08:51:24.038136Z","shell.execute_reply":"2024-05-21T08:51:24.060193Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"review       0\nsentiment    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Count the number of duplicate rows in the DataFrame and display the result.\ndf.duplicated().sum()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:24.063989Z","iopub.execute_input":"2024-05-21T08:51:24.064517Z","iopub.status.idle":"2024-05-21T08:51:24.267629Z","shell.execute_reply.started":"2024-05-21T08:51:24.064481Z","shell.execute_reply":"2024-05-21T08:51:24.266449Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"418"},"metadata":{}}]},{"cell_type":"code","source":"# Remove duplicate rows from the DataFrame and update the DataFrame in place.\ndf.drop_duplicates(inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:24.269586Z","iopub.execute_input":"2024-05-21T08:51:24.270015Z","iopub.status.idle":"2024-05-21T08:51:24.459975Z","shell.execute_reply.started":"2024-05-21T08:51:24.269979Z","shell.execute_reply":"2024-05-21T08:51:24.458717Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Convert all text in the 'review' column to lowercase.\ndf['review'] = df['review'].str.lower()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:24.461597Z","iopub.execute_input":"2024-05-21T08:51:24.462019Z","iopub.status.idle":"2024-05-21T08:51:24.690385Z","shell.execute_reply.started":"2024-05-21T08:51:24.461984Z","shell.execute_reply":"2024-05-21T08:51:24.689191Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef remove_html_tags(text):\n    # Remove HTML tags from the given text if it is a string.\n    if isinstance(text, str):\n        pattern = re.compile('<.*?>')  # Regular expression to match HTML tags\n        return pattern.sub(r'', text)  # Replace HTML tags with an empty string\n    else:\n        return text  # Return the text as is if it's not a string\n\n# Apply the remove_html_tags function to the 'review' column to clean the text data.\ndf['review'] = df['review'].apply(remove_html_tags)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:24.691666Z","iopub.execute_input":"2024-05-21T08:51:24.691974Z","iopub.status.idle":"2024-05-21T08:51:24.925267Z","shell.execute_reply.started":"2024-05-21T08:51:24.691949Z","shell.execute_reply":"2024-05-21T08:51:24.924072Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:24.927323Z","iopub.execute_input":"2024-05-21T08:51:24.927710Z","iopub.status.idle":"2024-05-21T08:51:24.952162Z","shell.execute_reply.started":"2024-05-21T08:51:24.927679Z","shell.execute_reply":"2024-05-21T08:51:24.950823Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      one of the other reviewers has mentioned that ...  positive\n1      a wonderful little production. the filming tec...  positive\n2      i thought this was a wonderful way to spend ti...  positive\n3      basically there's a family where a little boy ...  negative\n4      petter mattei's \"love in the time of money\" is...  positive\n...                                                  ...       ...\n49995  i thought this movie did a down right good job...  positive\n49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  i am a catholic taught in parochial elementary...  negative\n49998  i'm going to have to disagree with the previou...  negative\n49999  no one expects the star trek movies to be high...  negative\n\n[49582 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production. the filming tec...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei's \"love in the time of money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>i thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>i am a catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>i'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>no one expects the star trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>49582 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def remove_url(text):\n    # Remove URLs from the given text if it is a string.\n    if isinstance(text, str):\n        pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n        return pattern.sub(r'', text)\n    else:\n        return text\n\n# Apply the remove_url function to the 'review' column to remove URLs from the text data.\ndf['review'] = df['review'].apply(remove_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:24.954937Z","iopub.execute_input":"2024-05-21T08:51:24.955391Z","iopub.status.idle":"2024-05-21T08:51:25.700647Z","shell.execute_reply.started":"2024-05-21T08:51:24.955352Z","shell.execute_reply":"2024-05-21T08:51:25.699528Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def remove_punc(text, exclude):\n    # Remove punctuation characters from the given text based on the specified exclusion list.\n    for char in exclude:\n        text = text.replace(char, '')  # Replace each punctuation character with an empty string\n    return text\n\nexclude = '''!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~'''  # Define a string of punctuation characters to exclude\n# Apply the remove_punc function to the 'review' column, excluding the specified punctuation characters.\ndf['review'] = df['review'].apply(lambda x: remove_punc(x, exclude))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:25.702081Z","iopub.execute_input":"2024-05-21T08:51:25.702513Z","iopub.status.idle":"2024-05-21T08:51:27.045602Z","shell.execute_reply.started":"2024-05-21T08:51:25.702476Z","shell.execute_reply":"2024-05-21T08:51:27.044390Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:27.047318Z","iopub.execute_input":"2024-05-21T08:51:27.047997Z","iopub.status.idle":"2024-05-21T08:51:27.062026Z","shell.execute_reply.started":"2024-05-21T08:51:27.047961Z","shell.execute_reply":"2024-05-21T08:51:27.060875Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      one of the other reviewers has mentioned that ...  positive\n1      a wonderful little production the filming tech...  positive\n2      i thought this was a wonderful way to spend ti...  positive\n3      basically theres a family where a little boy j...  negative\n4      petter matteis love in the time of money is a ...  positive\n...                                                  ...       ...\n49995  i thought this movie did a down right good job...  positive\n49996  bad plot bad dialogue bad acting idiotic direc...  negative\n49997  i am a catholic taught in parochial elementary...  negative\n49998  im going to have to disagree with the previous...  negative\n49999  no one expects the star trek movies to be high...  negative\n\n[49582 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production the filming tech...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically theres a family where a little boy j...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter matteis love in the time of money is a ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>i thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>i am a catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>im going to have to disagree with the previous...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>no one expects the star trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>49582 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nimport nltk\n\n# Download the stopwords corpus if not already downloaded\nnltk.download('stopwords')\n\n# Get the set of English stopwords\nstop_words = set(stopwords.words('english'))\n\ndef remove_stopwords(text):\n    # Remove stopwords from the given text if it is a string.\n    if isinstance(text, str):\n        new_text = []\n        for word in text.split():\n            if word.lower() not in stop_words:\n                new_text.append(word)\n        return \" \".join(new_text)\n    else:\n        return text\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:27.063219Z","iopub.execute_input":"2024-05-21T08:51:27.063537Z","iopub.status.idle":"2024-05-21T08:51:28.569016Z","shell.execute_reply.started":"2024-05-21T08:51:27.063511Z","shell.execute_reply":"2024-05-21T08:51:28.567894Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Apply the remove_stopwords function to the 'review' column to remove stopwords from the text data.\ndf['review'] = df['review'].apply(remove_stopwords)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:28.570909Z","iopub.execute_input":"2024-05-21T08:51:28.571365Z","iopub.status.idle":"2024-05-21T08:51:31.668495Z","shell.execute_reply.started":"2024-05-21T08:51:28.571326Z","shell.execute_reply":"2024-05-21T08:51:31.667283Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Create a new DataFrame 'df2' by sampling 25,000 random rows from the original DataFrame 'df'.\ndf2 = df.sample(25000)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:31.670411Z","iopub.execute_input":"2024-05-21T08:51:31.670847Z","iopub.status.idle":"2024-05-21T08:51:31.685549Z","shell.execute_reply.started":"2024-05-21T08:51:31.670809Z","shell.execute_reply":"2024-05-21T08:51:31.684511Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Count the occurrences of each unique value in the 'sentiment' column of the DataFrame 'df2' and display the result.\ndf2['sentiment'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:54:26.371922Z","iopub.execute_input":"2024-05-21T06:54:26.372291Z","iopub.status.idle":"2024-05-21T06:54:26.385518Z","shell.execute_reply.started":"2024-05-21T06:54:26.372262Z","shell.execute_reply":"2024-05-21T06:54:26.384487Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"sentiment\npositive    12594\nnegative    12406\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Create features (X) and target variable (y) from the DataFrame 'df2'.\n# X contains all rows and the first column of 'df2' (excluding the 'sentiment' column).\nX = df2.iloc[:, 0:1]\n\n# y contains the 'sentiment' column of 'df2'.\ny = df2['sentiment']\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:01.993460Z","iopub.status.busy":"2024-05-20T19:24:01.993116Z","iopub.status.idle":"2024-05-20T19:24:02.002609Z","shell.execute_reply":"2024-05-20T19:24:02.001088Z","shell.execute_reply.started":"2024-05-20T19:24:01.993429Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:02.004461Z","iopub.status.busy":"2024-05-20T19:24:02.004102Z","iopub.status.idle":"2024-05-20T19:24:02.018561Z","shell.execute_reply":"2024-05-20T19:24:02.017141Z","shell.execute_reply.started":"2024-05-20T19:24:02.004429Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":["38100    negative\n","26692    positive\n","39338    negative\n","906      positive\n","2455     positive\n","           ...   \n","4969     positive\n","34640    positive\n","9622     negative\n","25044    positive\n","2602     positive\n","Name: sentiment, Length: 25000, dtype: object"]},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize a LabelEncoder object\nencoder = LabelEncoder()\n\n# Encode the target variable 'y' into numerical values\ny = encoder.fit_transform(y)\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:02.801359Z","iopub.status.busy":"2024-05-20T19:24:02.800348Z","iopub.status.idle":"2024-05-20T19:24:02.815979Z","shell.execute_reply":"2024-05-20T19:24:02.814526Z","shell.execute_reply.started":"2024-05-20T19:24:02.801314Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize a LabelEncoder object\nencoder = LabelEncoder()\n\n# Encode the target variable 'y' into numerical values\ny = encoder.fit_transform(y)\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:03.370877Z","iopub.status.busy":"2024-05-20T19:24:03.370076Z","iopub.status.idle":"2024-05-20T19:24:03.378113Z","shell.execute_reply":"2024-05-20T19:24:03.376944Z","shell.execute_reply.started":"2024-05-20T19:24:03.370827Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:05.030775Z","iopub.status.busy":"2024-05-20T19:24:05.030352Z","iopub.status.idle":"2024-05-20T19:24:05.038199Z","shell.execute_reply":"2024-05-20T19:24:05.036790Z","shell.execute_reply.started":"2024-05-20T19:24:05.030743Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, ..., 0, 1, 1])"]},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets, with 80% for training and 20% for testing, using a random state for reproducibility\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:06.011152Z","iopub.status.busy":"2024-05-20T19:24:06.010312Z","iopub.status.idle":"2024-05-20T19:24:06.023294Z","shell.execute_reply":"2024-05-20T19:24:06.021950Z","shell.execute_reply.started":"2024-05-20T19:24:06.011108Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:08.125186Z","iopub.status.busy":"2024-05-20T19:24:08.124774Z","iopub.status.idle":"2024-05-20T19:24:08.132542Z","shell.execute_reply":"2024-05-20T19:24:08.131552Z","shell.execute_reply.started":"2024-05-20T19:24:08.125157Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":["(20000, 1)"]},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n# Initialize a CountVectorizer object to convert text data into a matrix of token counts\ncv = CountVectorizer()\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:11.205437Z","iopub.status.busy":"2024-05-20T19:24:11.204973Z","iopub.status.idle":"2024-05-20T19:24:11.211216Z","shell.execute_reply":"2024-05-20T19:24:11.209882Z","shell.execute_reply.started":"2024-05-20T19:24:11.205399Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# BOW","metadata":{}},{"cell_type":"code","source":"# Convert the text data in the 'review' column of X_train into a matrix of token counts\n# and transform the text data in the 'review' column of X_test using the same vocabulary\nX_train_bow = cv.fit_transform(X_train['review']).toarray()\nX_test_bow = cv.transform(X_test['review']).toarray()\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:13.380947Z","iopub.status.busy":"2024-05-20T19:24:13.380540Z","iopub.status.idle":"2024-05-20T19:24:23.748803Z","shell.execute_reply":"2024-05-20T19:24:23.746954Z","shell.execute_reply.started":"2024-05-20T19:24:13.380917Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X_train_bow.shape","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:23.751697Z","iopub.status.busy":"2024-05-20T19:24:23.751159Z","iopub.status.idle":"2024-05-20T19:24:23.761245Z","shell.execute_reply":"2024-05-20T19:24:23.759826Z","shell.execute_reply.started":"2024-05-20T19:24:23.751649Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":["(20000, 125268)"]},"metadata":{}}]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:25:42.286660Z","iopub.status.busy":"2024-05-20T19:25:42.286220Z","iopub.status.idle":"2024-05-20T19:25:42.292014Z","shell.execute_reply":"2024-05-20T19:25:42.290846Z","shell.execute_reply.started":"2024-05-20T19:25:42.286630Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import time\nfrom sklearn.naive_bayes import GaussianNB\n\n# Start timing the training process\nstart_time = time.time()\n\n# Initialize and train a Gaussian Naive Bayes model using the bag-of-words features\ngnb = GaussianNB()\ngnb.fit(X_train_bow, y_train)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:25:43.701032Z","iopub.status.busy":"2024-05-20T19:25:43.700161Z","iopub.status.idle":"2024-05-20T19:26:33.037710Z","shell.execute_reply":"2024-05-20T19:26:33.036598Z","shell.execute_reply.started":"2024-05-20T19:25:43.700986Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","output_type":"stream","text":"Total time: 49.33 seconds\n"}]},{"cell_type":"code","source":"# Start timing the prediction process\nstart_time = time.time()\n\n# Predict the labels for the test set using the trained Gaussian Naive Bayes model\ny_pred = gnb.predict(X_test_bow)\n\n# Calculate the accuracy score of the model\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the prediction process and calculate the total time taken\nend_time = time.time()\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:27:37.316667Z","iopub.status.busy":"2024-05-20T19:27:37.316091Z","iopub.status.idle":"2024-05-20T19:27:48.370702Z","shell.execute_reply":"2024-05-20T19:27:48.369383Z","shell.execute_reply.started":"2024-05-20T19:27:37.316625Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","output_type":"stream","text":"Total time: 11.05 seconds\n"}]},{"cell_type":"code","source":"confusion_matrix(y_test,y_pred)","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:27:48.373701Z","iopub.status.busy":"2024-05-20T19:27:48.373207Z","iopub.status.idle":"2024-05-20T19:27:48.385813Z","shell.execute_reply":"2024-05-20T19:27:48.384474Z","shell.execute_reply.started":"2024-05-20T19:27:48.373658Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":["array([[1882,  609],\n","       [1173, 1336]])"]},"metadata":{}}]},{"cell_type":"code","source":"# Start timing the training process\nstart_time = time.time()\n\n# Initialize and train a Random Forest Classifier using the bag-of-words features\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train_bow, y_train)\n\n# Predict the labels for the test set and calculate the accuracy score\ny_pred = rf.predict(X_test_bow)\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:27:58.715143Z","iopub.status.busy":"2024-05-20T19:27:58.714698Z","iopub.status.idle":"2024-05-20T19:38:17.970998Z","shell.execute_reply":"2024-05-20T19:38:17.969367Z","shell.execute_reply.started":"2024-05-20T19:27:58.715109Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","output_type":"stream","text":"Total time: 619.25 seconds\n"}]},{"cell_type":"code","source":"# Start timing the training process\nstart_time = time.time()\n\n# Initialize a CountVectorizer with a maximum of 3000 features\ncv = CountVectorizer(max_features=3000)\n\n# Convert the text data into bag-of-words features using the CountVectorizer\nX_train_bow = cv.fit_transform(X_train['review']).toarray()\nX_test_bow = cv.transform(X_test['review']).toarray()\n\n# Initialize and train a Random Forest Classifier using the bag-of-words features\nrf = RandomForestClassifier()\nrf.fit(X_train_bow, y_train)\n\n# Predict the labels for the test set and calculate the accuracy score\ny_pred = rf.predict(X_test_bow)\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:43:58.178874Z","iopub.status.busy":"2024-05-20T19:43:58.178110Z","iopub.status.idle":"2024-05-20T19:44:43.689158Z","shell.execute_reply":"2024-05-20T19:44:43.687669Z","shell.execute_reply.started":"2024-05-20T19:43:58.178833Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","output_type":"stream","text":"Total time: 45.50 seconds\n\n\n\nAccuracy: 0.83\n"}]},{"cell_type":"code","source":"# Start timing the training process\nstart_time = time.time()\n\n# Initialize a CountVectorizer with ngram_range=(1,2) and a maximum of 10000 features\ncv = CountVectorizer(ngram_range=(1,2), max_features=10000)\n\n# Convert the text data into bag-of-words features using the CountVectorizer\nX_train_bow = cv.fit_transform(X_train['review']).toarray()\nX_test_bow = cv.transform(X_test['review']).toarray()\n\n# Initialize and train a Random Forest Classifier using the bag-of-words features\nrf = RandomForestClassifier()\nrf.fit(X_train_bow, y_train)\n\n# Predict the labels for the test set and calculate the accuracy score\ny_pred = rf.predict(X_test_bow)\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T20:16:53.973577Z","iopub.status.busy":"2024-05-20T20:16:53.973017Z","iopub.status.idle":"2024-05-20T20:19:11.847221Z","shell.execute_reply":"2024-05-20T20:19:11.845940Z","shell.execute_reply.started":"2024-05-20T20:16:53.973538Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","output_type":"stream","text":"Total time: 137.86 seconds\n\n\n\nAccuracy: 0.85\n"}]},{"cell_type":"markdown","source":"## using tfidf","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize a TfidfVectorizer object\ntfidf = TfidfVectorizer()\n\n# Convert the text data into TF-IDF features using the TfidfVectorizer\nX_train_tfidf = tfidf.fit_transform(X_train['review']).toarray()\nX_test_tfidf = tfidf.transform(X_test['review'])\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T20:21:32.458322Z","iopub.status.busy":"2024-05-20T20:21:32.457795Z","iopub.status.idle":"2024-05-20T20:21:50.326372Z","shell.execute_reply":"2024-05-20T20:21:50.324866Z","shell.execute_reply.started":"2024-05-20T20:21:32.458284Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Start timing the training process\nstart_time = time.time()\n\n# Initialize and train a Random Forest Classifier using the TF-IDF features\nrf = RandomForestClassifier()\nrf.fit(X_train_tfidf, y_train)\n\n# Predict the labels for the test set and calculate the accuracy score\ny_pred = rf.predict(X_test_tfidf)\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.execute_input":"2024-05-20T20:22:10.643977Z","iopub.status.busy":"2024-05-20T20:22:10.642383Z","iopub.status.idle":"2024-05-20T20:32:08.863820Z","shell.execute_reply":"2024-05-20T20:32:08.862698Z","shell.execute_reply.started":"2024-05-20T20:22:10.643914Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","output_type":"stream","text":"Total time: 598.21 seconds\n\n\n\nAccuracy: 0.85\n"}]},{"cell_type":"code","source":"# df chnging from my pc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  word2vec","metadata":{}},{"cell_type":"code","source":"# Create a new DataFrame 'df3' by sampling 25,000 random rows from the original DataFrame 'df'.\ndf3 = df.sample(25000)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:48.802958Z","iopub.execute_input":"2024-05-21T08:51:48.803374Z","iopub.status.idle":"2024-05-21T08:51:48.814596Z","shell.execute_reply.started":"2024-05-21T08:51:48.803344Z","shell.execute_reply":"2024-05-21T08:51:48.813372Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df3","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:50.702419Z","iopub.execute_input":"2024-05-21T08:51:50.703517Z","iopub.status.idle":"2024-05-21T08:51:50.714729Z","shell.execute_reply.started":"2024-05-21T08:51:50.703479Z","shell.execute_reply":"2024-05-21T08:51:50.713505Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n19974  sadness nostalgia permeate late chrysanthemums...  positive\n20669  seen season 1 far great wide variety people st...  positive\n46743  heyif going make documentary leonard cohen try...  negative\n6925   movie become iconic standin great america fame...  positive\n17734  bridget fonda disappointed several times years...  positive\n...                                                  ...       ...\n8406   rating 1010 master piecesome years ago heard s...  positive\n33929  didnt think absolutely horrible people apparen...  negative\n42192  kinda interested movie trashy cannibal flick t...  negative\n35866  sorry couldnt expressive summary two words see...  negative\n27050  resistible ultimately harmless film version ch...  negative\n\n[25000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19974</th>\n      <td>sadness nostalgia permeate late chrysanthemums...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>20669</th>\n      <td>seen season 1 far great wide variety people st...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>46743</th>\n      <td>heyif going make documentary leonard cohen try...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>6925</th>\n      <td>movie become iconic standin great america fame...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>17734</th>\n      <td>bridget fonda disappointed several times years...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8406</th>\n      <td>rating 1010 master piecesome years ago heard s...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>33929</th>\n      <td>didnt think absolutely horrible people apparen...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>42192</th>\n      <td>kinda interested movie trashy cannibal flick t...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>35866</th>\n      <td>sorry couldnt expressive summary two words see...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>27050</th>\n      <td>resistible ultimately harmless film version ch...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import gensim","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:51:51.946683Z","iopub.execute_input":"2024-05-21T08:51:51.947249Z","iopub.status.idle":"2024-05-21T08:52:02.427423Z","shell.execute_reply.started":"2024-05-21T08:51:51.947220Z","shell.execute_reply":"2024-05-21T08:52:02.426239Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from nltk import sent_tokenize\nfrom gensim.utils import simple_preprocess\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:52:02.428965Z","iopub.execute_input":"2024-05-21T08:52:02.429510Z","iopub.status.idle":"2024-05-21T08:52:02.433922Z","shell.execute_reply.started":"2024-05-21T08:52:02.429479Z","shell.execute_reply":"2024-05-21T08:52:02.432683Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"story = []\nfor doc in df['review']:\n    raw_sent = sent_tokenize(doc)\n    for sent in raw_sent:\n        story.append(simple_preprocess(sent))\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:52:02.435272Z","iopub.execute_input":"2024-05-21T08:52:02.435999Z","iopub.status.idle":"2024-05-21T08:52:16.874497Z","shell.execute_reply.started":"2024-05-21T08:52:02.435967Z","shell.execute_reply":"2024-05-21T08:52:16.873350Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\n\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:52:16.877159Z","iopub.execute_input":"2024-05-21T08:52:16.877529Z","iopub.status.idle":"2024-05-21T08:52:16.883825Z","shell.execute_reply.started":"2024-05-21T08:52:16.877498Z","shell.execute_reply":"2024-05-21T08:52:16.882468Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.build_vocab(story)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:52:16.885246Z","iopub.execute_input":"2024-05-21T08:52:16.885590Z","iopub.status.idle":"2024-05-21T08:52:20.238236Z","shell.execute_reply.started":"2024-05-21T08:52:16.885564Z","shell.execute_reply":"2024-05-21T08:52:20.236959Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model.train(story, total_examples=model.corpus_count, epochs=model.epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:52:20.239543Z","iopub.execute_input":"2024-05-21T08:52:20.239875Z","iopub.status.idle":"2024-05-21T08:52:55.012791Z","shell.execute_reply.started":"2024-05-21T08:52:20.239849Z","shell.execute_reply":"2024-05-21T08:52:55.011668Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(27679461, 29337830)"},"metadata":{}}]},{"cell_type":"code","source":"len(model.wv.index_to_key)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:52:55.014241Z","iopub.execute_input":"2024-05-21T08:52:55.014678Z","iopub.status.idle":"2024-05-21T08:52:55.021898Z","shell.execute_reply.started":"2024-05-21T08:52:55.014638Z","shell.execute_reply":"2024-05-21T08:52:55.020634Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"79940"},"metadata":{}}]},{"cell_type":"code","source":"def document_vector(doc):\n    # remove out-of-vocabulary words\n    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n    return np.mean(model.\n\nwv[doc], axis=0)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:52:55.023149Z","iopub.execute_input":"2024-05-21T08:52:55.023480Z","iopub.status.idle":"2024-05-21T08:52:55.031972Z","shell.execute_reply.started":"2024-05-21T08:52:55.023454Z","shell.execute_reply":"2024-05-21T08:52:55.030681Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"document_vector(df['review'].values[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:58:34.504640Z","iopub.execute_input":"2024-05-21T08:58:34.505089Z","iopub.status.idle":"2024-05-21T08:58:34.578285Z","shell.execute_reply.started":"2024-05-21T08:58:34.505061Z","shell.execute_reply":"2024-05-21T08:58:34.577130Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"array([-0.3681902 ,  0.49927786, -0.4478875 , -0.01066552,  0.14469494,\n       -0.44855216,  0.64326835,  0.30390143, -0.30793142, -0.18585789,\n       -0.01618404, -0.0596287 , -0.16270535, -0.206     ,  0.271342  ,\n        0.05046678,  0.3922921 , -0.2628789 ,  0.1531301 , -0.0386527 ,\n        0.19151935,  0.12482971,  0.05407229, -0.24450637,  0.5499226 ,\n       -0.06907693, -0.534649  , -0.15872858,  0.5457526 , -0.08906814,\n        0.5957868 ,  0.18658324, -0.35394207, -0.19746433,  0.01261288,\n        0.08122812, -0.11232699,  0.10941853, -0.5004749 , -0.34077418,\n       -0.5049931 , -0.14367674,  0.3859841 , -0.21285929,  0.05563477,\n       -0.05343244, -0.25569478, -0.28929642, -0.3665362 ,  0.4221344 ,\n        0.35848558, -0.05893759, -0.02955231, -0.17262425, -0.2967486 ,\n       -0.22124352,  0.33544353,  0.43521315, -0.22738284,  0.22682592,\n        0.33261043,  0.16556473,  0.00720006,  0.315832  , -0.49369213,\n       -0.23363689, -0.2619096 ,  0.43102637, -0.01370412,  0.31687498,\n        0.2563121 ,  0.16332862,  0.42869923,  0.14659004,  0.25295734,\n        0.1495542 , -0.08213574,  0.32868597,  0.05519028, -0.14400373,\n       -0.18456489, -0.00709765, -0.13085826,  0.4293299 ,  0.24544413,\n       -0.28662348,  0.26265818,  0.567697  ,  0.26452592, -0.1884707 ,\n        0.5678895 ,  0.13124193, -0.00731233, -0.30079275,  0.5075262 ,\n        0.5675238 , -0.02567813, -0.2272559 ,  0.16638044,  0.33050257],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n\nstart_time = time.time()\n\nX = []\nfor doc in tqdm(df['review'].values):\n    X.append(document_vector(doc))\n\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:58:35.840313Z","iopub.execute_input":"2024-05-21T08:58:35.840697Z","iopub.status.idle":"2024-05-21T09:33:06.730168Z","shell.execute_reply.started":"2024-05-21T08:58:35.840670Z","shell.execute_reply":"2024-05-21T09:33:06.728855Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49582/49582 [34:30<00:00, 23.94it/s] ","output_type":"stream"},{"name":"stdout","text":"Total time: 2070.88 seconds\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"X = np.array(X)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:33:06.732353Z","iopub.execute_input":"2024-05-21T09:33:06.732701Z","iopub.status.idle":"2024-05-21T09:33:06.796986Z","shell.execute_reply.started":"2024-05-21T09:33:06.732672Z","shell.execute_reply":"2024-05-21T09:33:06.795812Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"X[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:33:06.800106Z","iopub.execute_input":"2024-05-21T09:33:06.800486Z","iopub.status.idle":"2024-05-21T09:33:06.809723Z","shell.execute_reply.started":"2024-05-21T09:33:06.800457Z","shell.execute_reply":"2024-05-21T09:33:06.808449Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"array([-0.3681902 ,  0.49927786, -0.4478875 , -0.01066552,  0.14469494,\n       -0.44855216,  0.64326835,  0.30390143, -0.30793142, -0.18585789,\n       -0.01618404, -0.0596287 , -0.16270535, -0.206     ,  0.271342  ,\n        0.05046678,  0.3922921 , -0.2628789 ,  0.1531301 , -0.0386527 ,\n        0.19151935,  0.12482971,  0.05407229, -0.24450637,  0.5499226 ,\n       -0.06907693, -0.534649  , -0.15872858,  0.5457526 , -0.08906814,\n        0.5957868 ,  0.18658324, -0.35394207, -0.19746433,  0.01261288,\n        0.08122812, -0.11232699,  0.10941853, -0.5004749 , -0.34077418,\n       -0.5049931 , -0.14367674,  0.3859841 , -0.21285929,  0.05563477,\n       -0.05343244, -0.25569478, -0.28929642, -0.3665362 ,  0.4221344 ,\n        0.35848558, -0.05893759, -0.02955231, -0.17262425, -0.2967486 ,\n       -0.22124352,  0.33544353,  0.43521315, -0.22738284,  0.22682592,\n        0.33261043,  0.16556473,  0.00720006,  0.315832  , -0.49369213,\n       -0.23363689, -0.2619096 ,  0.43102637, -0.01370412,  0.31687498,\n        0.2563121 ,  0.16332862,  0.42869923,  0.14659004,  0.25295734,\n        0.1495542 , -0.08213574,  0.32868597,  0.05519028, -0.14400373,\n       -0.18456489, -0.00709765, -0.13085826,  0.4293299 ,  0.24544413,\n       -0.28662348,  0.26265818,  0.567697  ,  0.26452592, -0.1884707 ,\n        0.5678895 ,  0.13124193, -0.00731233, -0.30079275,  0.5075262 ,\n        0.5675238 , -0.02567813, -0.2272559 ,  0.16638044,  0.33050257],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ny = encoder.fit_transform(df['sentiment'])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:33:06.812220Z","iopub.execute_input":"2024-05-21T09:33:06.812588Z","iopub.status.idle":"2024-05-21T09:33:06.831908Z","shell.execute_reply.started":"2024-05-21T09:33:06.812560Z","shell.execute_reply":"2024-05-21T09:33:06.830514Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:33:06.833740Z","iopub.execute_input":"2024-05-21T09:33:06.834403Z","iopub.status.idle":"2024-05-21T09:33:06.843516Z","shell.execute_reply.started":"2024-05-21T09:33:06.834358Z","shell.execute_reply":"2024-05-21T09:33:06.842384Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, ..., 0, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y ,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:33:06.844951Z","iopub.execute_input":"2024-05-21T09:33:06.846189Z","iopub.status.idle":"2024-05-21T09:33:06.868463Z","shell.execute_reply.started":"2024-05-21T09:33:06.846151Z","shell.execute_reply":"2024-05-21T09:33:06.867494Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:33:06.869745Z","iopub.execute_input":"2024-05-21T09:33:06.870081Z","iopub.status.idle":"2024-05-21T09:33:07.092552Z","shell.execute_reply.started":"2024-05-21T09:33:06.870054Z","shell.execute_reply":"2024-05-21T09:33:07.091429Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred = rf.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:33:07.093914Z","iopub.execute_input":"2024-05-21T09:33:07.094595Z","iopub.status.idle":"2024-05-21T09:34:01.850134Z","shell.execute_reply.started":"2024-05-21T09:33:07.094551Z","shell.execute_reply":"2024-05-21T09:34:01.849002Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.8430977110013109"},"metadata":{}}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:34:01.853439Z","iopub.execute_input":"2024-05-21T09:34:01.853768Z","iopub.status.idle":"2024-05-21T09:34:01.870404Z","shell.execute_reply.started":"2024-05-21T09:34:01.853742Z","shell.execute_reply":"2024-05-21T09:34:01.869390Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      one reviewers mentioned watching 1 oz episode ...  positive\n1      wonderful little production filming technique ...  positive\n2      thought wonderful way spend time hot summer we...  positive\n3      basically theres family little boy jake thinks...  negative\n4      petter matteis love time money visually stunni...  positive\n...                                                  ...       ...\n49995  thought movie right good job wasnt creative or...  positive\n49996  bad plot bad dialogue bad acting idiotic direc...  negative\n49997  catholic taught parochial elementary schools n...  negative\n49998  im going disagree previous comment side maltin...  negative\n49999  one expects star trek movies high art fans exp...  negative\n\n[49582 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one reviewers mentioned watching 1 oz episode ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonderful little production filming technique ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically theres family little boy jake thinks...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter matteis love time money visually stunni...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>thought movie right good job wasnt creative or...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>catholic taught parochial elementary schools n...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>im going disagree previous comment side maltin...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>one expects star trek movies high art fans exp...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>49582 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}