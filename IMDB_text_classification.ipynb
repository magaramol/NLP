{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-20T19:23:38.156296Z","iopub.status.busy":"2024-05-20T19:23:38.155248Z","iopub.status.idle":"2024-05-20T19:23:39.537512Z","shell.execute_reply":"2024-05-20T19:23:39.536480Z","shell.execute_reply.started":"2024-05-20T19:23:38.156240Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:43.346752Z","iopub.status.busy":"2024-05-20T19:23:43.345335Z","iopub.status.idle":"2024-05-20T19:23:44.755024Z","shell.execute_reply":"2024-05-20T19:23:44.753709Z","shell.execute_reply.started":"2024-05-20T19:23:43.346707Z"},"trusted":true},"outputs":[],"source":["# Read the CSV file containing the IMDB movie reviews dataset into a DataFrame.\n","df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:44.757401Z","iopub.status.busy":"2024-05-20T19:23:44.756941Z","iopub.status.idle":"2024-05-20T19:23:44.788968Z","shell.execute_reply":"2024-05-20T19:23:44.787608Z","shell.execute_reply.started":"2024-05-20T19:23:44.757368Z"},"trusted":true},"outputs":[{"data":{"text/plain":["sentiment\n","positive    25000\n","negative    25000\n","Name: count, dtype: int64"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Count the occurrences of each unique value in the 'sentiment' column of the DataFrame and display the result.\n","df['sentiment'].value_counts()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:44.790736Z","iopub.status.busy":"2024-05-20T19:23:44.790398Z","iopub.status.idle":"2024-05-20T19:23:44.823753Z","shell.execute_reply":"2024-05-20T19:23:44.822393Z","shell.execute_reply.started":"2024-05-20T19:23:44.790708Z"},"trusted":true},"outputs":[{"data":{"text/plain":["review       0\n","sentiment    0\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Check for missing values in each column of the DataFrame and display the total count of missing values for each column.\n","df.isnull().sum()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:44.827231Z","iopub.status.busy":"2024-05-20T19:23:44.826748Z","iopub.status.idle":"2024-05-20T19:23:45.047649Z","shell.execute_reply":"2024-05-20T19:23:45.046305Z","shell.execute_reply.started":"2024-05-20T19:23:44.827185Z"},"trusted":true},"outputs":[{"data":{"text/plain":["418"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Count the number of duplicate rows in the DataFrame and display the result.\n","df.duplicated().sum()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:45.051350Z","iopub.status.busy":"2024-05-20T19:23:45.050167Z","iopub.status.idle":"2024-05-20T19:23:45.270773Z","shell.execute_reply":"2024-05-20T19:23:45.269323Z","shell.execute_reply.started":"2024-05-20T19:23:45.051303Z"},"trusted":true},"outputs":[],"source":["# Remove duplicate rows from the DataFrame and update the DataFrame in place.\n","df.drop_duplicates(inplace=True)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:45.355309Z","iopub.status.busy":"2024-05-20T19:23:45.354880Z","iopub.status.idle":"2024-05-20T19:23:45.587843Z","shell.execute_reply":"2024-05-20T19:23:45.586534Z","shell.execute_reply.started":"2024-05-20T19:23:45.355276Z"},"trusted":true},"outputs":[],"source":["# Convert all text in the 'review' column to lowercase.\n","df['review'] = df['review'].str.lower()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:45.825698Z","iopub.status.busy":"2024-05-20T19:23:45.825262Z","iopub.status.idle":"2024-05-20T19:23:46.100065Z","shell.execute_reply":"2024-05-20T19:23:46.098984Z","shell.execute_reply.started":"2024-05-20T19:23:45.825663Z"},"trusted":true},"outputs":[],"source":["import re\n","\n","def remove_html_tags(text):\n","    # Remove HTML tags from the given text if it is a string.\n","    if isinstance(text, str):\n","        pattern = re.compile('<.*?>')  # Regular expression to match HTML tags\n","        return pattern.sub(r'', text)  # Replace HTML tags with an empty string\n","    else:\n","        return text  # Return the text as is if it's not a string\n","\n","# Apply the remove_html_tags function to the 'review' column to clean the text data.\n","df['review'] = df['review'].apply(remove_html_tags)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:46.348631Z","iopub.status.busy":"2024-05-20T19:23:46.347596Z","iopub.status.idle":"2024-05-20T19:23:46.372272Z","shell.execute_reply":"2024-05-20T19:23:46.370832Z","shell.execute_reply.started":"2024-05-20T19:23:46.348577Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a wonderful little production. the filming tec...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>i thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>petter mattei's \"love in the time of money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>i thought this movie did a down right good job...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>i am a catholic taught in parochial elementary...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>i'm going to have to disagree with the previou...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>no one expects the star trek movies to be high...</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>49582 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  review sentiment\n","0      one of the other reviewers has mentioned that ...  positive\n","1      a wonderful little production. the filming tec...  positive\n","2      i thought this was a wonderful way to spend ti...  positive\n","3      basically there's a family where a little boy ...  negative\n","4      petter mattei's \"love in the time of money\" is...  positive\n","...                                                  ...       ...\n","49995  i thought this movie did a down right good job...  positive\n","49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n","49997  i am a catholic taught in parochial elementary...  negative\n","49998  i'm going to have to disagree with the previou...  negative\n","49999  no one expects the star trek movies to be high...  negative\n","\n","[49582 rows x 2 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:46.720350Z","iopub.status.busy":"2024-05-20T19:23:46.719963Z","iopub.status.idle":"2024-05-20T19:23:48.334712Z","shell.execute_reply":"2024-05-20T19:23:48.333568Z","shell.execute_reply.started":"2024-05-20T19:23:46.720321Z"},"trusted":true},"outputs":[],"source":["def remove_url(text):\n","    # Remove URLs from the given text if it is a string.\n","    if isinstance(text, str):\n","        pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n","        return pattern.sub(r'', text)\n","    else:\n","        return text\n","\n","# Apply the remove_url function to the 'review' column to remove URLs from the text data.\n","df['review'] = df['review'].apply(remove_url)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:48.337353Z","iopub.status.busy":"2024-05-20T19:23:48.336977Z","iopub.status.idle":"2024-05-20T19:23:49.752446Z","shell.execute_reply":"2024-05-20T19:23:49.751358Z","shell.execute_reply.started":"2024-05-20T19:23:48.337322Z"},"trusted":true},"outputs":[],"source":["def remove_punc(text, exclude):\n","    # Remove punctuation characters from the given text based on the specified exclusion list.\n","    for char in exclude:\n","        text = text.replace(char, '')  # Replace each punctuation character with an empty string\n","    return text\n","\n","exclude = '''!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~'''  # Define a string of punctuation characters to exclude\n","# Apply the remove_punc function to the 'review' column, excluding the specified punctuation characters.\n","df['review'] = df['review'].apply(lambda x: remove_punc(x, exclude))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:49.755276Z","iopub.status.busy":"2024-05-20T19:23:49.754823Z","iopub.status.idle":"2024-05-20T19:23:49.770492Z","shell.execute_reply":"2024-05-20T19:23:49.769334Z","shell.execute_reply.started":"2024-05-20T19:23:49.755234Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a wonderful little production the filming tech...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>i thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>basically theres a family where a little boy j...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>petter matteis love in the time of money is a ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>i thought this movie did a down right good job...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>i am a catholic taught in parochial elementary...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>im going to have to disagree with the previous...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>no one expects the star trek movies to be high...</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>49582 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  review sentiment\n","0      one of the other reviewers has mentioned that ...  positive\n","1      a wonderful little production the filming tech...  positive\n","2      i thought this was a wonderful way to spend ti...  positive\n","3      basically theres a family where a little boy j...  negative\n","4      petter matteis love in the time of money is a ...  positive\n","...                                                  ...       ...\n","49995  i thought this movie did a down right good job...  positive\n","49996  bad plot bad dialogue bad acting idiotic direc...  negative\n","49997  i am a catholic taught in parochial elementary...  negative\n","49998  im going to have to disagree with the previous...  negative\n","49999  no one expects the star trek movies to be high...  negative\n","\n","[49582 rows x 2 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:55.365527Z","iopub.status.busy":"2024-05-20T19:23:55.365121Z","iopub.status.idle":"2024-05-20T19:23:57.742922Z","shell.execute_reply":"2024-05-20T19:23:57.741604Z","shell.execute_reply.started":"2024-05-20T19:23:55.365472Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["from nltk.corpus import stopwords\n","import nltk\n","\n","# Download the stopwords corpus if not already downloaded\n","nltk.download('stopwords')\n","\n","# Get the set of English stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","def remove_stopwords(text):\n","    # Remove stopwords from the given text if it is a string.\n","    if isinstance(text, str):\n","        new_text = []\n","        for word in text.split():\n","            if word.lower() not in stop_words:\n","                new_text.append(word)\n","        return \" \".join(new_text)\n","    else:\n","        return text\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:23:57.746355Z","iopub.status.busy":"2024-05-20T19:23:57.745521Z","iopub.status.idle":"2024-05-20T19:24:01.954967Z","shell.execute_reply":"2024-05-20T19:24:01.953426Z","shell.execute_reply.started":"2024-05-20T19:23:57.746295Z"},"trusted":true},"outputs":[],"source":["# Apply the remove_stopwords function to the 'review' column to remove stopwords from the text data.\n","df['review'] = df['review'].apply(remove_stopwords)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:01.957713Z","iopub.status.busy":"2024-05-20T19:24:01.957299Z","iopub.status.idle":"2024-05-20T19:24:01.973860Z","shell.execute_reply":"2024-05-20T19:24:01.972579Z","shell.execute_reply.started":"2024-05-20T19:24:01.957677Z"},"trusted":true},"outputs":[],"source":["# Create a new DataFrame 'df2' by sampling 25,000 random rows from the original DataFrame 'df'.\n","df2 = df.sample(25000)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:01.976871Z","iopub.status.busy":"2024-05-20T19:24:01.976423Z","iopub.status.idle":"2024-05-20T19:24:01.991790Z","shell.execute_reply":"2024-05-20T19:24:01.990451Z","shell.execute_reply.started":"2024-05-20T19:24:01.976835Z"},"trusted":true},"outputs":[{"data":{"text/plain":["sentiment\n","positive    12591\n","negative    12409\n","Name: count, dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Count the occurrences of each unique value in the 'sentiment' column of the DataFrame 'df2' and display the result.\n","df2['sentiment'].value_counts()\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:01.993460Z","iopub.status.busy":"2024-05-20T19:24:01.993116Z","iopub.status.idle":"2024-05-20T19:24:02.002609Z","shell.execute_reply":"2024-05-20T19:24:02.001088Z","shell.execute_reply.started":"2024-05-20T19:24:01.993429Z"},"trusted":true},"outputs":[],"source":["# Create features (X) and target variable (y) from the DataFrame 'df2'.\n","# X contains all rows and the first column of 'df2' (excluding the 'sentiment' column).\n","X = df2.iloc[:, 0:1]\n","\n","# y contains the 'sentiment' column of 'df2'.\n","y = df2['sentiment']\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:02.004461Z","iopub.status.busy":"2024-05-20T19:24:02.004102Z","iopub.status.idle":"2024-05-20T19:24:02.018561Z","shell.execute_reply":"2024-05-20T19:24:02.017141Z","shell.execute_reply.started":"2024-05-20T19:24:02.004429Z"},"trusted":true},"outputs":[{"data":{"text/plain":["38100    negative\n","26692    positive\n","39338    negative\n","906      positive\n","2455     positive\n","           ...   \n","4969     positive\n","34640    positive\n","9622     negative\n","25044    positive\n","2602     positive\n","Name: sentiment, Length: 25000, dtype: object"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:02.801359Z","iopub.status.busy":"2024-05-20T19:24:02.800348Z","iopub.status.idle":"2024-05-20T19:24:02.815979Z","shell.execute_reply":"2024-05-20T19:24:02.814526Z","shell.execute_reply.started":"2024-05-20T19:24:02.801314Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Initialize a LabelEncoder object\n","encoder = LabelEncoder()\n","\n","# Encode the target variable 'y' into numerical values\n","y = encoder.fit_transform(y)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:03.370877Z","iopub.status.busy":"2024-05-20T19:24:03.370076Z","iopub.status.idle":"2024-05-20T19:24:03.378113Z","shell.execute_reply":"2024-05-20T19:24:03.376944Z","shell.execute_reply.started":"2024-05-20T19:24:03.370827Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Initialize a LabelEncoder object\n","encoder = LabelEncoder()\n","\n","# Encode the target variable 'y' into numerical values\n","y = encoder.fit_transform(y)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:05.030775Z","iopub.status.busy":"2024-05-20T19:24:05.030352Z","iopub.status.idle":"2024-05-20T19:24:05.038199Z","shell.execute_reply":"2024-05-20T19:24:05.036790Z","shell.execute_reply.started":"2024-05-20T19:24:05.030743Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([0, 1, 0, ..., 0, 1, 1])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:06.011152Z","iopub.status.busy":"2024-05-20T19:24:06.010312Z","iopub.status.idle":"2024-05-20T19:24:06.023294Z","shell.execute_reply":"2024-05-20T19:24:06.021950Z","shell.execute_reply.started":"2024-05-20T19:24:06.011108Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets, with 80% for training and 20% for testing, using a random state for reproducibility\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:08.125186Z","iopub.status.busy":"2024-05-20T19:24:08.124774Z","iopub.status.idle":"2024-05-20T19:24:08.132542Z","shell.execute_reply":"2024-05-20T19:24:08.131552Z","shell.execute_reply.started":"2024-05-20T19:24:08.125157Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20000, 1)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:11.205437Z","iopub.status.busy":"2024-05-20T19:24:11.204973Z","iopub.status.idle":"2024-05-20T19:24:11.211216Z","shell.execute_reply":"2024-05-20T19:24:11.209882Z","shell.execute_reply.started":"2024-05-20T19:24:11.205399Z"},"trusted":true},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Initialize a CountVectorizer object to convert text data into a matrix of token counts\n","cv = CountVectorizer()\n"]},{"cell_type":"markdown","metadata":{},"source":["# BOW"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:13.380947Z","iopub.status.busy":"2024-05-20T19:24:13.380540Z","iopub.status.idle":"2024-05-20T19:24:23.748803Z","shell.execute_reply":"2024-05-20T19:24:23.746954Z","shell.execute_reply.started":"2024-05-20T19:24:13.380917Z"},"trusted":true},"outputs":[],"source":["# Convert the text data in the 'review' column of X_train into a matrix of token counts\n","# and transform the text data in the 'review' column of X_test using the same vocabulary\n","X_train_bow = cv.fit_transform(X_train['review']).toarray()\n","X_test_bow = cv.transform(X_test['review']).toarray()\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:24:23.751697Z","iopub.status.busy":"2024-05-20T19:24:23.751159Z","iopub.status.idle":"2024-05-20T19:24:23.761245Z","shell.execute_reply":"2024-05-20T19:24:23.759826Z","shell.execute_reply.started":"2024-05-20T19:24:23.751649Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20000, 125268)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["X_train_bow.shape"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:25:42.286660Z","iopub.status.busy":"2024-05-20T19:25:42.286220Z","iopub.status.idle":"2024-05-20T19:25:42.292014Z","shell.execute_reply":"2024-05-20T19:25:42.290846Z","shell.execute_reply.started":"2024-05-20T19:25:42.286630Z"},"trusted":true},"outputs":[],"source":["import time"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:25:43.701032Z","iopub.status.busy":"2024-05-20T19:25:43.700161Z","iopub.status.idle":"2024-05-20T19:26:33.037710Z","shell.execute_reply":"2024-05-20T19:26:33.036598Z","shell.execute_reply.started":"2024-05-20T19:25:43.700986Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total time: 49.33 seconds\n"]}],"source":["import time\n","from sklearn.naive_bayes import GaussianNB\n","\n","# Start timing the training process\n","start_time = time.time()\n","\n","# Initialize and train a Gaussian Naive Bayes model using the bag-of-words features\n","gnb = GaussianNB()\n","gnb.fit(X_train_bow, y_train)\n","\n","# End timing the training process and calculate the total time taken\n","end_time = time.time()\n","print(f\"Total time: {end_time - start_time:.2f} seconds\")\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:27:37.316667Z","iopub.status.busy":"2024-05-20T19:27:37.316091Z","iopub.status.idle":"2024-05-20T19:27:48.370702Z","shell.execute_reply":"2024-05-20T19:27:48.369383Z","shell.execute_reply.started":"2024-05-20T19:27:37.316625Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total time: 11.05 seconds\n"]}],"source":["# Start timing the prediction process\n","start_time = time.time()\n","\n","# Predict the labels for the test set using the trained Gaussian Naive Bayes model\n","y_pred = gnb.predict(X_test_bow)\n","\n","# Calculate the accuracy score of the model\n","from sklearn.metrics import accuracy_score\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# End timing the prediction process and calculate the total time taken\n","end_time = time.time()\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Total time: {end_time - start_time:.2f} seconds\")\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:27:48.373701Z","iopub.status.busy":"2024-05-20T19:27:48.373207Z","iopub.status.idle":"2024-05-20T19:27:48.385813Z","shell.execute_reply":"2024-05-20T19:27:48.384474Z","shell.execute_reply.started":"2024-05-20T19:27:48.373658Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[1882,  609],\n","       [1173, 1336]])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test,y_pred)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:27:58.715143Z","iopub.status.busy":"2024-05-20T19:27:58.714698Z","iopub.status.idle":"2024-05-20T19:38:17.970998Z","shell.execute_reply":"2024-05-20T19:38:17.969367Z","shell.execute_reply.started":"2024-05-20T19:27:58.715109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total time: 619.25 seconds\n"]}],"source":["# Start timing the training process\n","start_time = time.time()\n","\n","# Initialize and train a Random Forest Classifier using the bag-of-words features\n","from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier()\n","rf.fit(X_train_bow, y_train)\n","\n","# Predict the labels for the test set and calculate the accuracy score\n","y_pred = rf.predict(X_test_bow)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# End timing the training process and calculate the total time taken\n","end_time = time.time()\n","print(f\"Total time: {end_time - start_time:.2f} seconds\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T19:43:58.178874Z","iopub.status.busy":"2024-05-20T19:43:58.178110Z","iopub.status.idle":"2024-05-20T19:44:43.689158Z","shell.execute_reply":"2024-05-20T19:44:43.687669Z","shell.execute_reply.started":"2024-05-20T19:43:58.178833Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total time: 45.50 seconds\n","\n","Accuracy: 0.83\n"]}],"source":["# Start timing the training process\n","start_time = time.time()\n","\n","# Initialize a CountVectorizer with a maximum of 3000 features\n","cv = CountVectorizer(max_features=3000)\n","\n","# Convert the text data into bag-of-words features using the CountVectorizer\n","X_train_bow = cv.fit_transform(X_train['review']).toarray()\n","X_test_bow = cv.transform(X_test['review']).toarray()\n","\n","# Initialize and train a Random Forest Classifier using the bag-of-words features\n","rf = RandomForestClassifier()\n","rf.fit(X_train_bow, y_train)\n","\n","# Predict the labels for the test set and calculate the accuracy score\n","y_pred = rf.predict(X_test_bow)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# End timing the training process and calculate the total time taken\n","end_time = time.time()\n","print(f\"Total time: {end_time - start_time:.2f} seconds\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T20:16:53.973577Z","iopub.status.busy":"2024-05-20T20:16:53.973017Z","iopub.status.idle":"2024-05-20T20:19:11.847221Z","shell.execute_reply":"2024-05-20T20:19:11.845940Z","shell.execute_reply.started":"2024-05-20T20:16:53.973538Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total time: 137.86 seconds\n","\n","Accuracy: 0.85\n"]}],"source":["# Start timing the training process\n","start_time = time.time()\n","\n","# Initialize a CountVectorizer with ngram_range=(1,2) and a maximum of 10000 features\n","cv = CountVectorizer(ngram_range=(1,2), max_features=10000)\n","\n","# Convert the text data into bag-of-words features using the CountVectorizer\n","X_train_bow = cv.fit_transform(X_train['review']).toarray()\n","X_test_bow = cv.transform(X_test['review']).toarray()\n","\n","# Initialize and train a Random Forest Classifier using the bag-of-words features\n","rf = RandomForestClassifier()\n","rf.fit(X_train_bow, y_train)\n","\n","# Predict the labels for the test set and calculate the accuracy score\n","y_pred = rf.predict(X_test_bow)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# End timing the training process and calculate the total time taken\n","end_time = time.time()\n","print(f\"Total time: {end_time - start_time:.2f} seconds\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## using tfidf"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T20:21:32.458322Z","iopub.status.busy":"2024-05-20T20:21:32.457795Z","iopub.status.idle":"2024-05-20T20:21:50.326372Z","shell.execute_reply":"2024-05-20T20:21:50.324866Z","shell.execute_reply.started":"2024-05-20T20:21:32.458284Z"},"trusted":true},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Initialize a TfidfVectorizer object\n","tfidf = TfidfVectorizer()\n","\n","# Convert the text data into TF-IDF features using the TfidfVectorizer\n","X_train_tfidf = tfidf.fit_transform(X_train['review']).toarray()\n","X_test_tfidf = tfidf.transform(X_test['review'])\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T20:22:10.643977Z","iopub.status.busy":"2024-05-20T20:22:10.642383Z","iopub.status.idle":"2024-05-20T20:32:08.863820Z","shell.execute_reply":"2024-05-20T20:32:08.862698Z","shell.execute_reply.started":"2024-05-20T20:22:10.643914Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total time: 598.21 seconds\n","\n","Accuracy: 0.85\n"]}],"source":["# Start timing the training process\n","start_time = time.time()\n","\n","# Initialize and train a Random Forest Classifier using the TF-IDF features\n","rf = RandomForestClassifier()\n","rf.fit(X_train_tfidf, y_train)\n","\n","# Predict the labels for the test set and calculate the accuracy score\n","y_pred = rf.predict(X_test_tfidf)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# End timing the training process and calculate the total time taken\n","end_time = time.time()\n","print(f\"Total time: {end_time - start_time:.2f} seconds\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df chnging from my pc"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T20:47:05.273135Z","iopub.status.busy":"2024-05-20T20:47:05.272652Z","iopub.status.idle":"2024-05-20T20:47:05.292403Z","shell.execute_reply":"2024-05-20T20:47:05.291293Z","shell.execute_reply.started":"2024-05-20T20:47:05.273103Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one reviewers mentioned watching 1 oz episode ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wonderful little production filming technique ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>thought wonderful way spend time hot summer we...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>basically theres family little boy jake thinks...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>petter matteis love time money visually stunni...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>thought movie right good job wasnt creative or...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>catholic taught parochial elementary schools n...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>im going disagree previous comment side maltin...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>one expects star trek movies high art fans exp...</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>49582 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  review sentiment\n","0      one reviewers mentioned watching 1 oz episode ...  positive\n","1      wonderful little production filming technique ...  positive\n","2      thought wonderful way spend time hot summer we...  positive\n","3      basically theres family little boy jake thinks...  negative\n","4      petter matteis love time money visually stunni...  positive\n","...                                                  ...       ...\n","49995  thought movie right good job wasnt creative or...  positive\n","49996  bad plot bad dialogue bad acting idiotic direc...  negative\n","49997  catholic taught parochial elementary schools n...  negative\n","49998  im going disagree previous comment side maltin...  negative\n","49999  one expects star trek movies high art fans exp...  negative\n","\n","[49582 rows x 2 columns]"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":134715,"sourceId":320111,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
