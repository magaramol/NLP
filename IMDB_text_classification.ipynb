{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-20T19:23:38.155248Z","iopub.execute_input":"2024-05-20T19:23:38.156296Z","iopub.status.idle":"2024-05-20T19:23:39.537512Z","shell.execute_reply.started":"2024-05-20T19:23:38.156240Z","shell.execute_reply":"2024-05-20T19:23:39.536480Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read the CSV file containing the IMDB movie reviews dataset into a DataFrame.\ndf = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:43.345335Z","iopub.execute_input":"2024-05-20T19:23:43.346752Z","iopub.status.idle":"2024-05-20T19:23:44.755024Z","shell.execute_reply.started":"2024-05-20T19:23:43.346707Z","shell.execute_reply":"2024-05-20T19:23:44.753709Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Count the occurrences of each unique value in the 'sentiment' column of the DataFrame and display the result.\ndf['sentiment'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:44.756941Z","iopub.execute_input":"2024-05-20T19:23:44.757401Z","iopub.status.idle":"2024-05-20T19:23:44.788968Z","shell.execute_reply.started":"2024-05-20T19:23:44.757368Z","shell.execute_reply":"2024-05-20T19:23:44.787608Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"sentiment\npositive    25000\nnegative    25000\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values in each column of the DataFrame and display the total count of missing values for each column.\ndf.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:44.790398Z","iopub.execute_input":"2024-05-20T19:23:44.790736Z","iopub.status.idle":"2024-05-20T19:23:44.823753Z","shell.execute_reply.started":"2024-05-20T19:23:44.790708Z","shell.execute_reply":"2024-05-20T19:23:44.822393Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"review       0\nsentiment    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Count the number of duplicate rows in the DataFrame and display the result.\ndf.duplicated().sum()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:44.826748Z","iopub.execute_input":"2024-05-20T19:23:44.827231Z","iopub.status.idle":"2024-05-20T19:23:45.047649Z","shell.execute_reply.started":"2024-05-20T19:23:44.827185Z","shell.execute_reply":"2024-05-20T19:23:45.046305Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"418"},"metadata":{}}]},{"cell_type":"code","source":"# Remove duplicate rows from the DataFrame and update the DataFrame in place.\ndf.drop_duplicates(inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:45.050167Z","iopub.execute_input":"2024-05-20T19:23:45.051350Z","iopub.status.idle":"2024-05-20T19:23:45.270773Z","shell.execute_reply.started":"2024-05-20T19:23:45.051303Z","shell.execute_reply":"2024-05-20T19:23:45.269323Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Convert all text in the 'review' column to lowercase.\ndf['review'] = df['review'].str.lower()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:45.354880Z","iopub.execute_input":"2024-05-20T19:23:45.355309Z","iopub.status.idle":"2024-05-20T19:23:45.587843Z","shell.execute_reply.started":"2024-05-20T19:23:45.355276Z","shell.execute_reply":"2024-05-20T19:23:45.586534Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef remove_html_tags(text):\n    # Remove HTML tags from the given text if it is a string.\n    if isinstance(text, str):\n        pattern = re.compile('<.*?>')  # Regular expression to match HTML tags\n        return pattern.sub(r'', text)  # Replace HTML tags with an empty string\n    else:\n        return text  # Return the text as is if it's not a string\n\n# Apply the remove_html_tags function to the 'review' column to clean the text data.\ndf['review'] = df['review'].apply(remove_html_tags)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:45.825262Z","iopub.execute_input":"2024-05-20T19:23:45.825698Z","iopub.status.idle":"2024-05-20T19:23:46.100065Z","shell.execute_reply.started":"2024-05-20T19:23:45.825663Z","shell.execute_reply":"2024-05-20T19:23:46.098984Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:46.347596Z","iopub.execute_input":"2024-05-20T19:23:46.348631Z","iopub.status.idle":"2024-05-20T19:23:46.372272Z","shell.execute_reply.started":"2024-05-20T19:23:46.348577Z","shell.execute_reply":"2024-05-20T19:23:46.370832Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      one of the other reviewers has mentioned that ...  positive\n1      a wonderful little production. the filming tec...  positive\n2      i thought this was a wonderful way to spend ti...  positive\n3      basically there's a family where a little boy ...  negative\n4      petter mattei's \"love in the time of money\" is...  positive\n...                                                  ...       ...\n49995  i thought this movie did a down right good job...  positive\n49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  i am a catholic taught in parochial elementary...  negative\n49998  i'm going to have to disagree with the previou...  negative\n49999  no one expects the star trek movies to be high...  negative\n\n[49582 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production. the filming tec...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei's \"love in the time of money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>i thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>i am a catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>i'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>no one expects the star trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>49582 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def remove_url(text):\n    # Remove URLs from the given text if it is a string.\n    if isinstance(text, str):\n        pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n        return pattern.sub(r'', text)\n    else:\n        return text\n\n# Apply the remove_url function to the 'review' column to remove URLs from the text data.\ndf['review'] = df['review'].apply(remove_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:46.719963Z","iopub.execute_input":"2024-05-20T19:23:46.720350Z","iopub.status.idle":"2024-05-20T19:23:48.334712Z","shell.execute_reply.started":"2024-05-20T19:23:46.720321Z","shell.execute_reply":"2024-05-20T19:23:48.333568Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def remove_punc(text, exclude):\n    # Remove punctuation characters from the given text based on the specified exclusion list.\n    for char in exclude:\n        text = text.replace(char, '')  # Replace each punctuation character with an empty string\n    return text\n\nexclude = '''!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~'''  # Define a string of punctuation characters to exclude\n# Apply the remove_punc function to the 'review' column, excluding the specified punctuation characters.\ndf['review'] = df['review'].apply(lambda x: remove_punc(x, exclude))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:48.336977Z","iopub.execute_input":"2024-05-20T19:23:48.337353Z","iopub.status.idle":"2024-05-20T19:23:49.752446Z","shell.execute_reply.started":"2024-05-20T19:23:48.337322Z","shell.execute_reply":"2024-05-20T19:23:49.751358Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:49.754823Z","iopub.execute_input":"2024-05-20T19:23:49.755276Z","iopub.status.idle":"2024-05-20T19:23:49.770492Z","shell.execute_reply.started":"2024-05-20T19:23:49.755234Z","shell.execute_reply":"2024-05-20T19:23:49.769334Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      one of the other reviewers has mentioned that ...  positive\n1      a wonderful little production the filming tech...  positive\n2      i thought this was a wonderful way to spend ti...  positive\n3      basically theres a family where a little boy j...  negative\n4      petter matteis love in the time of money is a ...  positive\n...                                                  ...       ...\n49995  i thought this movie did a down right good job...  positive\n49996  bad plot bad dialogue bad acting idiotic direc...  negative\n49997  i am a catholic taught in parochial elementary...  negative\n49998  im going to have to disagree with the previous...  negative\n49999  no one expects the star trek movies to be high...  negative\n\n[49582 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production the filming tech...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically theres a family where a little boy j...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter matteis love in the time of money is a ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>i thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>i am a catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>im going to have to disagree with the previous...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>no one expects the star trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>49582 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nimport nltk\n\n# Download the stopwords corpus if not already downloaded\nnltk.download('stopwords')\n\n# Get the set of English stopwords\nstop_words = set(stopwords.words('english'))\n\ndef remove_stopwords(text):\n    # Remove stopwords from the given text if it is a string.\n    if isinstance(text, str):\n        new_text = []\n        for word in text.split():\n            if word.lower() not in stop_words:\n                new_text.append(word)\n        return \" \".join(new_text)\n    else:\n        return text\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:55.365121Z","iopub.execute_input":"2024-05-20T19:23:55.365527Z","iopub.status.idle":"2024-05-20T19:23:57.742922Z","shell.execute_reply.started":"2024-05-20T19:23:55.365472Z","shell.execute_reply":"2024-05-20T19:23:57.741604Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Apply the remove_stopwords function to the 'review' column to remove stopwords from the text data.\ndf['review'] = df['review'].apply(remove_stopwords)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:23:57.745521Z","iopub.execute_input":"2024-05-20T19:23:57.746355Z","iopub.status.idle":"2024-05-20T19:24:01.954967Z","shell.execute_reply.started":"2024-05-20T19:23:57.746295Z","shell.execute_reply":"2024-05-20T19:24:01.953426Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Create a new DataFrame 'df2' by sampling 25,000 random rows from the original DataFrame 'df'.\ndf2 = df.sample(25000)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:01.957299Z","iopub.execute_input":"2024-05-20T19:24:01.957713Z","iopub.status.idle":"2024-05-20T19:24:01.973860Z","shell.execute_reply.started":"2024-05-20T19:24:01.957677Z","shell.execute_reply":"2024-05-20T19:24:01.972579Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Count the occurrences of each unique value in the 'sentiment' column of the DataFrame 'df2' and display the result.\ndf2['sentiment'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:01.976423Z","iopub.execute_input":"2024-05-20T19:24:01.976871Z","iopub.status.idle":"2024-05-20T19:24:01.991790Z","shell.execute_reply.started":"2024-05-20T19:24:01.976835Z","shell.execute_reply":"2024-05-20T19:24:01.990451Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"sentiment\npositive    12591\nnegative    12409\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Create features (X) and target variable (y) from the DataFrame 'df2'.\n# X contains all rows and the first column of 'df2' (excluding the 'sentiment' column).\nX = df2.iloc[:, 0:1]\n\n# y contains the 'sentiment' column of 'df2'.\ny = df2['sentiment']\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:01.993116Z","iopub.execute_input":"2024-05-20T19:24:01.993460Z","iopub.status.idle":"2024-05-20T19:24:02.002609Z","shell.execute_reply.started":"2024-05-20T19:24:01.993429Z","shell.execute_reply":"2024-05-20T19:24:02.001088Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:02.004102Z","iopub.execute_input":"2024-05-20T19:24:02.004461Z","iopub.status.idle":"2024-05-20T19:24:02.018561Z","shell.execute_reply.started":"2024-05-20T19:24:02.004429Z","shell.execute_reply":"2024-05-20T19:24:02.017141Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"38100    negative\n26692    positive\n39338    negative\n906      positive\n2455     positive\n           ...   \n4969     positive\n34640    positive\n9622     negative\n25044    positive\n2602     positive\nName: sentiment, Length: 25000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize a LabelEncoder object\nencoder = LabelEncoder()\n\n# Encode the target variable 'y' into numerical values\ny = encoder.fit_transform(y)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:02.800348Z","iopub.execute_input":"2024-05-20T19:24:02.801359Z","iopub.status.idle":"2024-05-20T19:24:02.815979Z","shell.execute_reply.started":"2024-05-20T19:24:02.801314Z","shell.execute_reply":"2024-05-20T19:24:02.814526Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize a LabelEncoder object\nencoder = LabelEncoder()\n\n# Encode the target variable 'y' into numerical values\ny = encoder.fit_transform(y)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:03.370076Z","iopub.execute_input":"2024-05-20T19:24:03.370877Z","iopub.status.idle":"2024-05-20T19:24:03.378113Z","shell.execute_reply.started":"2024-05-20T19:24:03.370827Z","shell.execute_reply":"2024-05-20T19:24:03.376944Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:05.030352Z","iopub.execute_input":"2024-05-20T19:24:05.030775Z","iopub.status.idle":"2024-05-20T19:24:05.038199Z","shell.execute_reply.started":"2024-05-20T19:24:05.030743Z","shell.execute_reply":"2024-05-20T19:24:05.036790Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([0, 1, 0, ..., 0, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets, with 80% for training and 20% for testing, using a random state for reproducibility\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:06.010312Z","iopub.execute_input":"2024-05-20T19:24:06.011152Z","iopub.status.idle":"2024-05-20T19:24:06.023294Z","shell.execute_reply.started":"2024-05-20T19:24:06.011108Z","shell.execute_reply":"2024-05-20T19:24:06.021950Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:08.124774Z","iopub.execute_input":"2024-05-20T19:24:08.125186Z","iopub.status.idle":"2024-05-20T19:24:08.132542Z","shell.execute_reply.started":"2024-05-20T19:24:08.125157Z","shell.execute_reply":"2024-05-20T19:24:08.131552Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(20000, 1)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n# Initialize a CountVectorizer object to convert text data into a matrix of token counts\ncv = CountVectorizer()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:11.204973Z","iopub.execute_input":"2024-05-20T19:24:11.205437Z","iopub.status.idle":"2024-05-20T19:24:11.211216Z","shell.execute_reply.started":"2024-05-20T19:24:11.205399Z","shell.execute_reply":"2024-05-20T19:24:11.209882Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:11.955768Z","iopub.execute_input":"2024-05-20T19:24:11.956226Z","iopub.status.idle":"2024-05-20T19:24:11.961666Z","shell.execute_reply.started":"2024-05-20T19:24:11.956189Z","shell.execute_reply":"2024-05-20T19:24:11.960381Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Convert the text data in the 'review' column of X_train into a matrix of token counts\n# and transform the text data in the 'review' column of X_test using the same vocabulary\nX_train_bow = cv.fit_transform(X_train['review']).toarray()\nX_test_bow = cv.transform(X_test['review']).toarray()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:13.380540Z","iopub.execute_input":"2024-05-20T19:24:13.380947Z","iopub.status.idle":"2024-05-20T19:24:23.748803Z","shell.execute_reply.started":"2024-05-20T19:24:13.380917Z","shell.execute_reply":"2024-05-20T19:24:23.746954Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X_train_bow.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:24:23.751159Z","iopub.execute_input":"2024-05-20T19:24:23.751697Z","iopub.status.idle":"2024-05-20T19:24:23.761245Z","shell.execute_reply.started":"2024-05-20T19:24:23.751649Z","shell.execute_reply":"2024-05-20T19:24:23.759826Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(20000, 125268)"},"metadata":{}}]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:25:42.286220Z","iopub.execute_input":"2024-05-20T19:25:42.286660Z","iopub.status.idle":"2024-05-20T19:25:42.292014Z","shell.execute_reply.started":"2024-05-20T19:25:42.286630Z","shell.execute_reply":"2024-05-20T19:25:42.290846Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import time\nfrom sklearn.naive_bayes import GaussianNB\n\n# Start timing the training process\nstart_time = time.time()\n\n# Initialize and train a Gaussian Naive Bayes model using the bag-of-words features\ngnb = GaussianNB()\ngnb.fit(X_train_bow, y_train)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:25:43.700161Z","iopub.execute_input":"2024-05-20T19:25:43.701032Z","iopub.status.idle":"2024-05-20T19:26:33.037710Z","shell.execute_reply.started":"2024-05-20T19:25:43.700986Z","shell.execute_reply":"2024-05-20T19:26:33.036598Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Total time: 49.33 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"# Start timing the prediction process\nstart_time = time.time()\n\n# Predict the labels for the test set using the trained Gaussian Naive Bayes model\ny_pred = gnb.predict(X_test_bow)\n\n# Calculate the accuracy score of the model\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the prediction process and calculate the total time taken\nend_time = time.time()\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:27:37.316091Z","iopub.execute_input":"2024-05-20T19:27:37.316667Z","iopub.status.idle":"2024-05-20T19:27:48.370702Z","shell.execute_reply.started":"2024-05-20T19:27:37.316625Z","shell.execute_reply":"2024-05-20T19:27:48.369383Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Total time: 11.05 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"confusion_matrix(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:27:48.373207Z","iopub.execute_input":"2024-05-20T19:27:48.373701Z","iopub.status.idle":"2024-05-20T19:27:48.385813Z","shell.execute_reply.started":"2024-05-20T19:27:48.373658Z","shell.execute_reply":"2024-05-20T19:27:48.384474Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([[1882,  609],\n       [1173, 1336]])"},"metadata":{}}]},{"cell_type":"code","source":"# Start timing the training process\nstart_time = time.time()\n\n# Initialize and train a Random Forest Classifier using the bag-of-words features\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train_bow, y_train)\n\n# Predict the labels for the test set and calculate the accuracy score\ny_pred = rf.predict(X_test_bow)\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:27:58.714698Z","iopub.execute_input":"2024-05-20T19:27:58.715143Z","iopub.status.idle":"2024-05-20T19:38:17.970998Z","shell.execute_reply.started":"2024-05-20T19:27:58.715109Z","shell.execute_reply":"2024-05-20T19:38:17.969367Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Total time: 619.25 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:42:06.928860Z","iopub.execute_input":"2024-05-20T19:42:06.929731Z","iopub.status.idle":"2024-05-20T19:42:06.937602Z","shell.execute_reply.started":"2024-05-20T19:42:06.929683Z","shell.execute_reply":"2024-05-20T19:42:06.936695Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"accuracy_score: 85.2800\n","output_type":"stream"}]},{"cell_type":"code","source":"# Start timing the training process\nstart_time = time.time()\n\n# Initialize a CountVectorizer with a maximum of 3000 features\ncv = CountVectorizer(max_features=3000)\n\n# Convert the text data into bag-of-words features using the CountVectorizer\nX_train_bow = cv.fit_transform(X_train['review']).toarray()\nX_test_bow = cv.transform(X_test['review']).toarray()\n\n# Initialize and train a Random Forest Classifier using the bag-of-words features\nrf = RandomForestClassifier()\nrf.fit(X_train_bow, y_train)\n\n# Predict the labels for the test set and calculate the accuracy score\ny_pred = rf.predict(X_test_bow)\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T19:43:58.178110Z","iopub.execute_input":"2024-05-20T19:43:58.178874Z","iopub.status.idle":"2024-05-20T19:44:43.689158Z","shell.execute_reply.started":"2024-05-20T19:43:58.178833Z","shell.execute_reply":"2024-05-20T19:44:43.687669Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Total time: 45.50 seconds\nAccuracy: 0.83\n","output_type":"stream"}]},{"cell_type":"code","source":"# Start timing the training process\nstart_time = time.time()\n\n# Initialize a CountVectorizer with ngram_range=(1,2) and a maximum of 10000 features\ncv = CountVectorizer(ngram_range=(1,2), max_features=10000)\n\n# Convert the text data into bag-of-words features using the CountVectorizer\nX_train_bow = cv.fit_transform(X_train['review']).toarray()\nX_test_bow = cv.transform(X_test['review']).toarray()\n\n# Initialize and train a Random Forest Classifier using the bag-of-words features\nrf = RandomForestClassifier()\nrf.fit(X_train_bow, y_train)\n\n# Predict the labels for the test set and calculate the accuracy score\ny_pred = rf.predict(X_test_bow)\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T20:16:53.973017Z","iopub.execute_input":"2024-05-20T20:16:53.973577Z","iopub.status.idle":"2024-05-20T20:19:11.847221Z","shell.execute_reply.started":"2024-05-20T20:16:53.973538Z","shell.execute_reply":"2024-05-20T20:19:11.845940Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Total time: 137.86 seconds\nAccuracy: 0.85\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## using tfidf","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize a TfidfVectorizer object\ntfidf = TfidfVectorizer()\n\n# Convert the text data into TF-IDF features using the TfidfVectorizer\nX_train_tfidf = tfidf.fit_transform(X_train['review']).toarray()\nX_test_tfidf = tfidf.transform(X_test['review'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T20:21:32.457795Z","iopub.execute_input":"2024-05-20T20:21:32.458322Z","iopub.status.idle":"2024-05-20T20:21:50.326372Z","shell.execute_reply.started":"2024-05-20T20:21:32.458284Z","shell.execute_reply":"2024-05-20T20:21:50.324866Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Start timing the training process\nstart_time = time.time()\n\n# Initialize and train a Random Forest Classifier using the TF-IDF features\nrf = RandomForestClassifier()\nrf.fit(X_train_tfidf, y_train)\n\n# Predict the labels for the test set and calculate the accuracy score\ny_pred = rf.predict(X_test_tfidf)\naccuracy = accuracy_score(y_test, y_pred)\n\n# End timing the training process and calculate the total time taken\nend_time = time.time()\nprint(f\"Total time: {end_time - start_time:.2f} seconds\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T20:22:10.642383Z","iopub.execute_input":"2024-05-20T20:22:10.643977Z","iopub.status.idle":"2024-05-20T20:32:08.863820Z","shell.execute_reply.started":"2024-05-20T20:22:10.643914Z","shell.execute_reply":"2024-05-20T20:32:08.862698Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Total time: 598.21 seconds\nAccuracy: 0.85\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}