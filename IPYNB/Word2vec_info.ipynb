{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In This code we will use word2vec to GOT books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec README\n",
    "\n",
    "Word2Vec is a popular neural network-based model used for generating word embeddings, where words are mapped to vectors of real numbers in a continuous vector space. This README covers the advantages of Word2Vec, the types of Word2Vec models, and the differences between Continuous Bag of Words (CBOW) and Skip-Gram.\n",
    "\n",
    "## Advantages of Word2Vec\n",
    "\n",
    "1. **Capture Semantic Meaning**: Word2Vec captures the semantic relationships between words. Words with similar meanings are positioned closely in the vector space, enabling the model to understand context and similarity.\n",
    "2. **Low Dimension**: Word2Vec generates low-dimensional vectors, which reduce computational complexity and improve the efficiency of downstream tasks.\n",
    "3. **Dense Vectors**: The vectors produced are dense, meaning they have fewer zero values. This helps in tackling overfitting issues, as it allows the model to generalize better from the training data.\n",
    "\n",
    "## Types of Word2Vec Models\n",
    "\n",
    "### Continuous Bag of Words (CBOW)\n",
    "\n",
    "The CBOW model predicts the target word (center word) using the context words (surrounding words). This model is effective for smaller datasets and tends to converge faster due to the averaging of context words. It works by averaging the context word vectors and using this average to predict the target word.\n",
    "\n",
    "**Characteristics of CBOW**:\n",
    "- Suitable for small datasets.\n",
    "- Faster training due to context averaging.\n",
    "- Predicts a word based on its context.\n",
    "\n",
    "### Skip-Gram\n",
    "\n",
    "The Skip-Gram model does the opposite of CBOW. It predicts the context words from the target word (center word). Skip-Gram is more suitable for larger datasets and can capture a wider range of word relationships. It works by using the target word to predict the probability of each context word.\n",
    "\n",
    "**Characteristics of Skip-Gram**:\n",
    "- Suitable for large datasets.\n",
    "- Slower training but captures more detailed word relationships.\n",
    "- Predicts context words based on a single word.\n",
    "\n",
    "## Usage\n",
    "\n",
    "To train a Word2Vec model, you can use popular libraries such as Gensim in Python. Below is an example of how to train a Word2Vec model using Gensim:\n",
    "\n",
    "```python\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    ['word1', 'word2', 'word3'],\n",
    "    ['word4', 'word5', 'word6'],\n",
    "    # Add more sentences here\n",
    "]\n",
    "\n",
    "# Training the Word2Vec model using CBOW\n",
    "model_cbow = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Training the Word2Vec model using Skip-Gram\n",
    "model_skipgram = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Save the model\n",
    "model_cbow.save(\"word2vec_cbow.model\")\n",
    "model_skipgram.save(\"word2vec_skipgram.model\")\n",
    "\n",
    "# Load the model\n",
    "model_cbow = Word2Vec.load(\"word2vec_cbow.model\")\n",
    "model_skipgram = Word2Vec.load(\"word2vec_skipgram.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Word2Vec is a powerful technique for creating word embeddings that capture semantic meaning and relationships between words. By choosing between CBOW and Skip-Gram models based on the dataset size, you can optimize the performance and efficiency of your natural language processing tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
